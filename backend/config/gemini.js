import { GoogleGenerativeAI } from '@google/generative-ai';
import * as dotenv from 'dotenv';

dotenv.config();

// Initialize Google Generative AI with API key
const API_KEY = process.env.GEMINI_API_KEY;

if (!API_KEY) {
  console.warn('GEMINI_API_KEY not found in environment variables. AI validation will be disabled.');
}

const genAI = API_KEY ? new GoogleGenerativeAI(API_KEY) : null;

/**
 * Validates evidence using Gemini AI to detect AI-generated content
 * @param {Object} evidence - The evidence object to validate
 * @returns {Promise<Object>} - Validation results
 */
export const validateEvidence = async (evidence) => {
  if (!genAI) {
    console.warn('Gemini AI not initialized. Skipping evidence validation.');
    return {
      isVerified: false,
      verificationNotes: 'AI validation not available',
      confidenceScore: 0,
      isFlagged: false
    };
  }

  try {
    // Select the model
    const model = genAI.getGenerativeModel({ model: 'gemini-pro' });
    
    // Prepare the content to analyze based on evidence type
    let contentToAnalyze = '';
    
    if (evidence.evidenceType === 'testimonial') {
      contentToAnalyze = evidence.testimonialContent;
    } else if (evidence.description) {
      contentToAnalyze = evidence.description;
    } else {
      return {
        isVerified: false,
        verificationNotes: 'Not enough textual content to verify',
        confidenceScore: 0,
        isFlagged: false
      };
    }
    
    // Skip if content is too short
    if (contentToAnalyze.length < 50) {
      return {
        isVerified: false,
        verificationNotes: 'Content is too short for reliable verification',
        confidenceScore: 0,
        isFlagged: false
      };
    }

    // Create the prompt for AI analysis
    const prompt = `
      Please analyze the following content and determine if it appears to be AI-generated.
      Provide your assessment in JSON format with these fields:
      1. isAIGenerated (boolean): your determination if the content was likely generated by AI
      2. confidenceScore (number 0-1): how confident you are in this assessment
      3. reasoning (string): brief explanation of your reasoning
      4. contentType (string): the type of content you believe this is (personal account, factual reporting, creative writing, etc.)
      
      Content to analyze:
      "${contentToAnalyze}"
    `;

    // Generate content
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();
    
    // Extract JSON from the response (handle potential formatting issues)
    let jsonMatch = text.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      throw new Error('Could not parse JSON from AI response');
    }
    
    // Parse the JSON response
    const analysis = JSON.parse(jsonMatch[0]);
    
    // Return formatted verification results
    return {
      isVerified: !analysis.isAIGenerated,
      verificationNotes: analysis.reasoning,
      confidenceScore: analysis.confidenceScore,
      contentType: analysis.contentType,
      isFlagged: analysis.isAIGenerated && analysis.confidenceScore > 0.7
    };
  } catch (error) {
    console.error('Error validating evidence with AI:', error);
    return {
      isVerified: false,
      verificationNotes: 'Error during AI validation: ' + error.message,
      confidenceScore: 0,
      isFlagged: false
    };
  }
};

/**
 * Verify evidence media for authenticity using AI
 * @param {Object} evidence - The evidence object with media file
 * @returns {Promise<Object>} - Verification results
 */
export const verifyEvidenceMedia = async (evidence) => {
  if (!genAI) {
    console.warn('Gemini AI not initialized. Skipping evidence media verification.');
    return {
      isAuthentic: false,
      verificationNotes: 'AI verification not available',
      confidenceScore: 0,
      isFlagged: false
    };
  }

  try {
    // Skip verification if no media file
    if (!evidence.mediaFile || !evidence.mediaFile.url) {
      return {
        isAuthentic: false,
        verificationNotes: 'No media file to verify',
        confidenceScore: 0,
        isFlagged: false
      };
    }

    // Use the right model depending on the evidence type
    const modelName = evidence.evidenceType === 'photo' || evidence.evidenceType === 'document' 
      ? 'gemini-pro-vision' 
      : 'gemini-pro';
    
    const model = genAI.getGenerativeModel({ model: modelName });
    
    // For photo/image evidence, use vision capabilities
    if ((evidence.evidenceType === 'photo' || evidence.evidenceType === 'document') && evidence.mediaFile.url) {
      // Create parts with image URL
      const imageParts = [
        {
          inlineData: {
            mimeType: evidence.mediaFile.fileType,
            data: await fetchImageAsBase64(evidence.mediaFile.url) // Implement this helper function
          }
        },
        {
          text: `Please analyze this image that was submitted as evidence for a civic campaign.
            Title: "${evidence.title}"
            Description: "${evidence.description}"
            
            Please determine:
            1. If this appears to be AI-generated content or manipulated
            2. If the image appears authentic or shows signs of being fabricated
            3. Your confidence level in this assessment
            
            Response format:
            {
              "isAuthentic": boolean,
              "confidenceScore": number (0-1),
              "analysisNotes": string,
              "detectedIssues": [strings],
              "mediaType": string
            }`
        }
      ];

      // Generate content with image analysis
      const result = await model.generateContent(imageParts);
      const response = await result.response;
      const text = response.text();
      
      // Extract JSON from the response
      const jsonMatch = text.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        throw new Error('Could not parse JSON from AI response');
      }
      
      // Parse the JSON response
      const analysis = JSON.parse(jsonMatch[0]);
      
      return {
        isAuthentic: analysis.isAuthentic,
        verificationNotes: analysis.analysisNotes || '',
        detectedIssues: analysis.detectedIssues || [],
        confidenceScore: analysis.confidenceScore,
        mediaType: analysis.mediaType || evidence.evidenceType,
        isFlagged: !analysis.isAuthentic && analysis.confidenceScore > 0.65
      };
    } 
    // For testimonial/text evidence, use text analysis
    else if (evidence.evidenceType === 'testimonial' && evidence.testimonialContent) {
      // We already have validateEvidence for text content
      return await validateEvidence(evidence);
    }
    // For video/audio evidence
    else if ((evidence.evidenceType === 'video' || evidence.evidenceType === 'audio') && evidence.mediaFile.url) {
      // For now, we can do a simple analysis with the file information and description
      // In a full implementation, you'd want to analyze frames or audio waveforms
      
      const prompt = `
        I need you to analyze metadata about a ${evidence.evidenceType} file that was uploaded as evidence.
        
        File information:
        - Title: "${evidence.title}"
        - Description: "${evidence.description}"
        - File type: ${evidence.mediaFile.fileType}
        - File size: ${evidence.mediaFile.fileSize} bytes
        - Duration: ${evidence.mediaFile.duration || 'unknown'} seconds
        
        Based on this information, please assess:
        1. If this appears suspicious or likely to be manipulated content
        2. What factors might indicate authenticity issues
        
        Please provide your analysis in JSON format:
        {
          "isAuthentic": boolean (likelihood of authenticity),
          "confidenceScore": number (0-1),
          "analysisNotes": string,
          "detectedIssues": [strings]
        }`;
      
      const result = await model.generateContent(prompt);
      const response = await result.response;
      const text = response.text();
      
      // Extract JSON from the response
      const jsonMatch = text.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        throw new Error('Could not parse JSON from AI response');
      }
      
      // Parse the JSON response
      const analysis = JSON.parse(jsonMatch[0]);
      
      return {
        isAuthentic: analysis.isAuthentic,
        verificationNotes: analysis.analysisNotes || '',
        detectedIssues: analysis.detectedIssues || [],
        confidenceScore: analysis.confidenceScore,
        isFlagged: !analysis.isAuthentic && analysis.confidenceScore > 0.65
      };
    }
    
    // Default case for unsupported evidence types
    return {
      isAuthentic: false,
      verificationNotes: 'Unsupported evidence type for verification',
      confidenceScore: 0,
      isFlagged: false
    };
  } catch (error) {
    console.error('Error verifying evidence media with AI:', error);
    return {
      isAuthentic: false,
      verificationNotes: 'Error during AI media verification: ' + error.message,
      confidenceScore: 0,
      isFlagged: true // Flag for manual review when verification fails
    };
  }
};

/**
 * Helper function to fetch an image and convert it to base64
 */
async function fetchImageAsBase64(imageUrl) {
  try {
    // For Cloudinary or remote URLs
    if (imageUrl.startsWith('http')) {
      const response = await fetch(imageUrl);
      const arrayBuffer = await response.arrayBuffer();
      const buffer = Buffer.from(arrayBuffer);
      return buffer.toString('base64');
    } 
    // For local files (though this shouldn't be common in your setup)
    else {
      const fs = await import('fs/promises');
      const buffer = await fs.readFile(imageUrl);
      return buffer.toString('base64');
    }
  } catch (error) {
    console.error('Error fetching image:', error);
    throw error;
  }
}

/**
 * Process evidence through AI validation and update the database record
 */
export const processEvidenceValidation = async (evidenceId, Campaign, CampaignEvidence) => {
  try {
    // Fetch the evidence record
    const evidence = await CampaignEvidence.findById(evidenceId);
    
    if (!evidence) {
      console.error(`Evidence ID ${evidenceId} not found`);
      return;
    }
    
    // Perform AI validation
    const validationResults = await validateEvidence(evidence);
    
    // Update the evidence record with validation results
    evidence.verification = {
      ...evidence.verification,
      isVerified: validationResults.isVerified,
      verificationMethod: 'technical_analysis',
      verificationDate: new Date(),
      verificationNotes: validationResults.verificationNotes,
      confidenceScore: validationResults.confidenceScore
    };
    
    // If evidence is flagged as potentially AI-generated, update status
    if (validationResults.isFlagged) {
      evidence.status = 'under_review';
      evidence.reviewNotes = 'Flagged by AI as potentially generated content. Requires human review.';
    } else if (validationResults.isVerified) {
      evidence.status = 'accepted';
    }
    
    // Save the updated evidence record
    await evidence.save();
    
    console.log(`Evidence ${evidenceId} validation completed. Verified: ${validationResults.isVerified}`);
    
    return validationResults;
  } catch (error) {
    console.error(`Error processing evidence validation for ${evidenceId}:`, error);
    throw error;
  }
};